# k8s 安装部署

### 集群

master111 node112 node113

1 配置

~~~shell
#配置主机名
hostnamectl set-hostname master
hostnamectl set-hostname node112
hostnamectl set-hostname node

# 3台主机，安装基础软件
yum -y install wget bash-completion net-tools vim

# 安装常用软件
yum install -y net-tools iproute lrzsz vim bash-completion wget tree bridge-utils unzip bind-utils git gcc

# 修改/etc/hosts
cat >> /etc/hosts << EOF
192.168.56.136  node-00
192.168.56.135  master-00
EOF

# 关闭selinux
sudo sed -i 's/^SELINUX=enforcing$/SELINUX=disabled/' /etc/selinux/config && sudo setenforce 0

# 同步时间
sudo yum install -y chrony
sudo systemctl restart chronyd && sudo systemctl enable chronyd && sudo  systemctl status chronyd

#关闭防火墙
sudo systemctl stop firewalld && sudo systemctl disable firewalld

#关闭swap分区
sudo sed -i '11s/\/dev/# \/dev/g' /etc/fstab && sudo  swapoff -a

#yum源设置
mkdir /etc/yum.repos.d/ori &&  mv /etc/yum.repos.d/CentOS-* /etc/yum.repos.d/ori/
sudo bash -c "cat > /etc/yum.repos.d/kubenetes.repo" << EOF
# kubenetes.repo
#
# The mirror system uses the connecting IP address of the client and the
# update status of each mirror to pick mirrors that are updated to and
# geographically close to the client.  You should use this for CentOS updates
# unless you are manually picking other mirrors.
#
# If the mirrorlist= does not work for you, as a fall back you can try the
# remarked out baseurl= line instead.
#
#

[base]
name=CentOS-$releasever - Base
baseurl=https://mirrors.tuna.tsinghua.edu.cn/centos/$releasever/os/$basearch/
#mirrorlist=http://mirrorlist.centos.org/?release=$releasever&arch=$basearch&repo=os
gpgcheck=1
gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-8

#released updates
[updates]
name=CentOS-$releasever - Updates
baseurl=https://mirrors.tuna.tsinghua.edu.cn/centos/$releasever/updates/$basearch/
#mirrorlist=http://mirrorlist.centos.org/?release=$releasever&arch=$basearch&repo=updates
gpgcheck=1
gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-8

#additional packages that may be useful
[extras]
name=CentOS-$releasever - Extras
baseurl=https://mirrors.tuna.tsinghua.edu.cn/centos/$releasever/extras/$basearch/
#mirrorlist=http://mirrorlist.centos.org/?release=$releasever&arch=$basearch&repo=extras
gpgcheck=1
gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-8

#additional packages that extend functionality of existing packages
[centosplus]
name=CentOS-$releasever - Plus
baseurl=https://mirrors.tuna.tsinghua.edu.cn/centos/$releasever/centosplus/$basearch/
#mirrorlist=http://mirrorlist.centos.org/?release=$releasever&arch=$basearch&repo=centosplus
gpgcheck=1
enabled=0
gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-8

[aliyun-AppStream]
name=CentOS-$releasever - AppStream
baseurl=https://mirrors.aliyun.com/centos/$releasever/AppStream/$basearch/os/
gpgcheck=1
enabled=1
gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-centosofficial

[aliyun-BaseOS]
name=CentOS-$releasever - Base
baseurl=https://mirrors.aliyun.com/centos/$releasever/BaseOS/$basearch/os/
gpgcheck=1
enabled=1
gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-centosofficial

[aliyun-extras]
name=CentOS-$releasever - Extras
baseurl=https://mirrors.aliyun.com/centos/$releasever/extras/$basearch/os/
gpgcheck=1
enabled=1
gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-centosofficial
EOF
~~~

### 安装epel配置epel源

~~~shell
yum install -y epel-release

sudo bash -c "cat > /etc/yum.repos.d/epel.repo" << EOF
[epel]
name=Extra Packages for Enterprise Linux 8 - $basearch
baseurl=https://mirrors.tuna.tsinghua.edu.cn/epel/8/$basearch
#mirrorlist=https://mirrors.fedoraproject.org/metalink?repo=epel-8&arch=$basearch
failovermethod=priority
enabled=1
gpgcheck=1
gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL-8

[epel-debuginfo]
name=Extra Packages for Enterprise Linux 8 - $basearch - Debug
baseurl=https://mirrors.tuna.tsinghua.edu.cn/epel/8/$basearch/debug
#mirrorlist=https://mirrors.fedoraproject.org/metalink?repo=epel-debug-8&arch=$basearch
failovermethod=priority
enabled=0
gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL-8
gpgcheck=1

[epel-source]
name=Extra Packages for Enterprise Linux 8 - $basearch - Source
baseurl=https://mirrors.tuna.tsinghua.edu.cn/epel/7/SRPMS
#mirrorlist=https://mirrors.fedoraproject.org/metalink?repo=epel-source-8&arch=$basearch
failovermethod=priority
enabled=0
gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL-8
gpgcheck=1
EOF



yum clean all && yum makecache
~~~

### 配置IPVS内核

~~~shell
#默认情况下，Kube-proxy将在kubeadm部署的集群中以iptables模式运行
#需要注意的是，当内核版本大于4.19时，移除了nf_conntrack_ipv4模块，kubernetes官方建议使用#nf_conntrack代替，否则报错无法找到nf_conntrack_ipv4模块
yum install -y ipset ipvsadm
cat > /etc/sysconfig/modules/ipvs.modules <<EOF
#!/bin/bash
modprobe -- ip_vs
modprobe -- ip_vs_rr
modprobe -- ip_vs_wrr
modprobe -- ip_vs_sh
modprobe -- nf_conntrack
EOF

sudo chmod +x /etc/sysconfig/modules/ipvs.modules
sudo bash /etc/sysconfig/modules/ipvs.modules

~~~

### 配置内核参数

~~~shell
cat > /etc/sysctl.d/k8s.conf <<EOF
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
net.ipv4.ip_nonlocal_bind = 1
net.ipv4.ip_forward = 1
vm.swappiness=0
EOF

sudo modprobe br_netfilter
sudo sysctl -p /etc/sysctl.d/k8s.conf
~~~

### 打开文件数

~~~shell
echo "* soft nofile 65536" >> /etc/security/limits.conf
echo "* hard nofile 65536" >> /etc/security/limits.conf
~~~

### 安装docker

~~~shell
wget -P /etc/yum.repos.d/ http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo
yum install -y docker-ce
~~~

### docker配置修改和镜像加速

~~~shell
[ ! -d /etc/docker ] && mkdir /etc/docker

cat > /etc/docker/daemon.json <<EOF
{
  "exec-opts": ["native.cgroupdriver=systemd"],
  "log-driver": "json-file",
  "log-opts": {
    "max-size": "100m"
  },
  "storage-driver": "overlay2",
  "storage-opts": [
    "overlay2.override_kernel_check=true"
  ],
  "registry-mirrors": ["https://uyah70su.mirror.aliyuncs.com"]
}
EOF

# 启动docker
sudo systemctl daemon-reload && sudo systemctl restart docker && sudo systemctl enable docker
~~~

### 安装kubelet kubeadm kubectl

~~~shell
#kubelet 运行在 Cluster 所有节点上，负责启动 Pod 和容器。
#kubeadm 用于初始化 Cluster。
#kubectl 是 Kubernetes 命令行工具。通过 kubectl 可以部署和管理应用，查看各种资源，创建、删除和更新各
#种组件。
cat <<EOF > /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64
enabled=1
gpgcheck=1
repo_gpgcheck=1
gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg
EOF

# 默认安装最新版本，此处为1.15.1
sudo yum install -y kubeadm-1.20.0 kubelet-1.20.0 kubectl-1.20.0
systemctl enable kubelet && systemctl start kubelet


sudo yum remove  kubeadm 删除高版本的应用
~~~

### 启动kubectl命令自动补全

~~~shell
# 安装并配置bash-completion
yum install -y bash-completion
echo 'source /usr/share/bash-completion/bash_completion' >> /etc/profile
source /etc/profile
echo "source <(kubectl completion bash)" >> ~/.bashrc
source ~/.bashrc
~~~

### 初始化Master

~~~shell
#使用kubeadm config print init-defaults可以打印集群初始化默认的使用的配置
#这里采用命令行方式初始化，注意默认镜像仓库由于在国外，不能访问，这里指定为阿里云镜像仓库
#需要注意这里使用的网络方案是flannel，注意CIDR

# kubernetes-version版本和前面安装的kubelet和kubectl一致


#查看版本号
kubectl version
##在选定的master主机上执行
kubeadm init --apiserver-advertise-address 192.168.1.111 --kubernetes-version="v1.20.1" --pod-network-cidr=10.244.0.0/16 --image-repository=registry.aliyuncs.com/google_containers | tee kubeadm-init.log


sudo kubeadm init --apiserver-advertise-address 192.168.56.135 --kubernetes-version="1.20.0" --pod-network-cidr=10.244.0.0/16 --image-repository=registry.aliyuncs.com/google_containers | tee kubeadm-init.log
sudo kubeadm init --apiserver-advertise-address 192.168.56.135 --kubernetes-version="1.20.0" --pod-network-cidr=10.244.0.0/16 --image-repository=registry.aliyuncs.com/k8sxio | tee kubeadm-init.log
~~~

### 如果找不到镜像 可以去dockers 下载然后修改tag,不过也不一定可以，可以试试。 不能翻墙最好不要用最新的镜像

```shell
[init] Using Kubernetes version: v1.21.1
[preflight] Running pre-flight checks
[preflight] Pulling images required for setting up a Kubernetes cluster
[preflight] This might take a minute or two, depending on the speed of your internet connection
[preflight] You can also perform this action in beforehand using 'kubeadm config images pull'
error execution phase preflight: [preflight] Some fatal errors occurred:
        [ERROR ImagePull]: failed to pull image registry.aliyuncs.com/google_containers/coredns/coredns:v1.8.0: output: Error response from daemon: pull access denied for registry.aliyuncs.com/google_containers/coredns/coredns, repository does not exist or may require 'docker login': denied: requested access to the resource is denied
, error: exit status 1
[preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...`
To see the stack trace of this error execute with --v=5 or higher
# 缺少 registry.aliyuncs.com/google_containers/coredns/coredns:v1.8.0 可以去docker 下载 coredns/coredns:v1.8.0 [docker pull coredns/coredns:v1.8.0 docker search coredns/coredns:v1.8.0]
# 然后修改镜像的tag  docker tag coredns/coredns:1.2.2  k8s.gcr.io/coredns:1.2.2 即可
```

### 配置kubectl

~~~shell
#无论在master节点或node节点，要能够执行kubectl命令必须进行以下配置
#root用户配置

cat << EOF >> ~/.bashrc
export KUBECONFIG=/etc/kubernetes/admin.conf
EOF
source ~/.bashrc

#普通用户配置
mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config
~~~

### 安装flannel

~~~shell
#下载flannel包，执行kube-flannel.yml


sudo wget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml

kubectl apply -f kube-flannel.yml
#或
kubectl create -f kube-flannel.yml

wget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/k8s-manifests/kube-flannel-rbac.yml
kubectl apply -f kube-flannel-rbac.yml

kubectl exec -ti <your-pod-name>  -n <your-namespace>  -- /bin/sh
~~~

### 卸载flannel

~~~shell
#卸载flannel网络步骤：
#第一步，在master节点删除flannel
kubectl delete -f kube-flannel.yml
~~~

### Linux内核升级

~~~shell
#查看有哪些内核
cat /boot/grub2/grub.cfg | grep menuentry

#指定开机从哪个内核启动
grub2-set-default "CentOS Linux (3.10.0-327.el7.x86_64) 7 (Core)"
#查看默认启动内核
grub2-editenv list


rpm -Uvh http://www.elrepo.org/elrepo-release-7.0-3.el7.elrepo.noarch.rpm
# 安装完成后检查 /boot/grub2/grub.cfg 中对应内核 menuentry 中是否包含 initrd16 配置，如果没有，再安装一次！
yum --enablerepo=elrepo-kernel install -y kernel-lt
# 设置开机从新内核启动，这个版本号不一定是对的
grub2-set-default 'CentOS Linux (4.4.248-1.el7.elrepo.x86_64) 7 (Core)'

~~~

### 各个node 拷贝

~~~shell
scp /etc/kubernetes/admin.conf root@192.168.1.113:/etc/kubernetes/
scp /etc/kubernetes/admin.conf root@192.168.1.112:/etc/kubernetes/
~~~

### 加入node节点

~~~shell
kubeadm join 192.168.1.111:6443 --token xwvyhb.6dvaqlrqy9gdi1hb \
    --discovery-token-ca-cert-hash sha256:4bdb084cce1083707a2b8dbe2e4618fe45dee54724f0d1912d930411c122a457
~~~

### kubernetes 常用命令

~~~shell
kubectl get nodes
kubectl get pods -n kube-system
kubectl get pods --all-namespaces

kubectl get pod -n kube-system -o wide
~~~

### harbor 配置node节点

~~~shell
#给各个node节点，添加配置信息
echo "192.168.1.110  www.harbor.mobi" >> /etc/hosts
~~~

### 使用harbor 集群  需要去github 下载安装包，harbor 依赖docker-compose ,如果从其可以使用 docker-compose up /stop 也可以去harbor解压包里面再次执行 sudo ./install 或者先执行 sudo ./prepare

~~~shell
docker pull wangyanglinux/myapp:v1

#每个节点node，都要运行得到配置安全认证
cat > /etc/docker/daemon.json <<EOF
{
  "insecure-registries": [
    "www.harbor.mobi"
  ]
}
EOF

#每个节点node，重启docker才生效
 systemctl restart docker

#给节点上传镜像，打标签
docker tag wangyanglinux/myapp:v1  www.harbor.mobi/library/wangyanglinux/myapp:v1
#节点上传镜像到harbor
docker push www.harbor.mobi/library/wangyanglinux/myapp:v1
#就可以到harbor仓库查看上传完成的镜像文件

#项目找到镜像文件，找到拉取命令
docker pull www.harbor.mobi/library/wangyanglinux/myapp@sha256:9eeca44ba2d410e54fccc54cbe9c021802aa8b9836a0bcf3d3229354e4c8870e

#在master节点，部署pod
kubectl run nginx-deployment --image=www.harbor.mobi/library/wangyanglinux/myapp:v1  --port=80 --rep                                            licas=1

#查看pod,运行所在的节点
kubectl get pod   -o wide

#也可以到pod，运行的node节点查看。只要运行pod，就会有pause
docker ps | grep nginx

#验证pod
curl 10.244.2.2
Hello MyApp | Version: v1 | <a href="hostname.html">Pod Name</a>
#执行，得pod名称
curl 10.244.2.2/hostname.html
~~~

## 删除pod

~~~shell
[root@master111 ~]# kubectl get po
NAME               READY   STATUS   RESTARTS   AGE
nginx-deployment   0/1     Error    6          10m
[root@master111 ~]# kubectl delete pods nginx-deployment
pod "nginx-deployment" deleted

~~~

### 集群资源分类

~~~shell
#名称空间
#kue-system
#只能获得默认的pod信息
kubectl get pod -n default

#集群级别:role

#元数据型:HPA 通过指标进行操作



~~~

### yaml

~~~shell
vi nginx.yaml
# API 版本号
apiVersion: apps/v1
# 类型，如：Pod/ReplicationController/Deployment/Service/Ingress
kind: Deployment
metadata:
  # Kind 的名称
  name: nginx-app
spec:
  selector:
    matchLabels:
      # 容器标签的名字，发布 Service 时，selector 需要和这里对应
      app: nginx
  # 部署的实例数量
  replicas: 2
  template:
    metadata:
      labels:
        app: nginx
    spec:
      # 配置容器，数组类型，说明可以配置多个容器
      containers:
      # 容器名称
      - name: nginx
        # 容器镜像
        image: www.harbor.mobi/library/wangyanglinux/myapp:v1
        # 只有镜像不存在时，才会进行镜像拉取
        imagePullPolicy: IfNotPresent
        ports:
        # Pod 端口
        - containerPort: 80

#以上保存

#执行
kubectl apply -f nginx.yaml
#查看
kubectl get po  -o wide
#验证
[root@master111 ~]# curl 10.244.1.7
Hello MyApp | Version: v1 | <a href="hostname.html">Pod Name</a>
[root@master111 ~]# curl 10.244.2.3
Hello MyApp | Version: v1 | <a href="hostname.html">Pod Name</a>
[root@master111 ~]# kubectl get po --help

#delete pod 自动重启
[root@master111 ~]# kubectl get po
NAME                         READY   STATUS    RESTARTS   AGE
nginx-app-654b68c4f7-f5vnv   1/1     Running   0          6m15s
nginx-app-654b68c4f7-htqlj   1/1     Running   0          6m15s
[root@master111 ~]# kubectl delete po nginx-app-654b68c4f7-htqlj
pod "nginx-app-654b68c4f7-htqlj" deleted
[root@master111 ~]# kubectl get po
NAME                         READY   STATUS    RESTARTS   AGE
nginx-app-654b68c4f7-f5vnv   1/1     Running   0          7m27s
nginx-app-654b68c4f7-znjdx   1/1     Running   0          54s

#查看指定的pod
kubectl describe pod nginx-app-654b68c4f7-znjdx

#举例
vim nginx-err.yaml
# API 版本号
apiVersion: apps/v1
# 类型，如：Pod/ReplicationController/Deployment/Service/Ingress
kind: Deployment
metadata:
  # Kind 的名称
  name: nginx-app
spec:
  selector:
    matchLabels:
      # 容器标签的名字，发布 Service 时，selector 需要和这里对应
      app: nginx
  # 部署的实例数量
  replicas: 2
  template:
    metadata:
      labels:
        app: nginx
    spec:
      # 配置容器，数组类型，说明可以配置多个容器
      containers:
      # 容器名称
      - name: nginx
        # 容器镜像
        image: www.harbor.mobi/library/wangyanglinux/myapp:v1
        # 只有镜像不存在时，才会进行镜像拉取
      - name: nginx-err
        image: www.harbor.mobi/library/wangyanglinux/myapp:v1

        # Pod 端口
#保存nginx-err.yaml

#运行
kubectl apply -f nginx-err.yaml
#描述
kubectl describe pod  nginx-app-d9f759787-5jkxr

#定位pod的错误
[root@master111 ~]# kubectl logs  nginx-app-d9f759787-5jkxr -c nginx-err
2020/12/20 02:46:57 [emerg] 1#1: bind() to 0.0.0.0:80 failed (98: Address in use)
nginx: [emerg] bind() to 0.0.0.0:80 failed (98: Address in use)
2020/12/20 02:46:57 [emerg] 1#1: bind() to 0.0.0.0:80 failed (98: Address in use)
nginx: [emerg] bind() to 0.0.0.0:80 failed (98: Address in use)
2020/12/20 02:46:57 [emerg] 1#1: bind() to 0.0.0.0:80 failed (98: Address in use)
nginx: [emerg] bind() to 0.0.0.0:80 failed (98: Address in use)
2020/12/20 02:46:57 [emerg] 1#1: bind() to 0.0.0.0:80 failed (98: Address in use)
nginx: [emerg] bind() to 0.0.0.0:80 failed (98: Address in use)
2020/12/20 02:46:57 [emerg] 1#1: bind() to 0.0.0.0:80 failed (98: Address in use)
nginx: [emerg] bind() to 0.0.0.0:80 failed (98: Address in use)
2020/12/20 02:46:57 [emerg] 1#1: still could not bind()
nginx: [emerg] still could not bind()

#处理有问题的pod,停止有副本的pod，删除部署再删除pod
[root@master111 ~]# kubectl get deployments
NAME        READY   UP-TO-DATE   AVAILABLE   AGE
nginx-app   0/2     2            0           37m
[root@master111 ~]# kubectl delete deployment nginx-app
deployment.apps "nginx-app" deleted
[root@master111 ~]# kubectl get po
NAME                        READY   STATUS        RESTARTS   AGE
nginx-app-d9f759787-j6gl4   0/2     Terminating   5          4m58s
nginx-app-d9f759787-kbm5c   0/2     Terminating   6          7m5s
[root@master111 ~]# kubectl get deployments
No resources found in default namespace.
[root@master111 ~]# kubectl delete pod nginx-app-d9f759787-j6gl4
pod "nginx-app-d9f759787-j6gl4" deleted
[root@master111 ~]# kubectl get po
No resources found in default namespace.

[root@master111 ~]# kubectl get po -o wide
NAME                         READY   STATUS    RESTARTS   AGE   IP            NODE      NOMINATED NODE   READINESS GATES
nginx-app-654b68c4f7-4mj7v   1/1     Running   0          10s   10.244.2.7    node113   <none>           <none>
nginx-app-654b68c4f7-w8hpw   1/1     Running   0          10s   10.244.1.10   node112   <none>           <none>
[root@master111 ~]# curl 10.244.2.7
Hello MyApp | Version: v1 | <a href="hostname.html">Pod Name</a>
[root@master111 ~]# curl 10.244.1.10
Hello MyApp | Version: v1 | <a href="hostname.html">Pod Name</a>


~~~

### 暴露服务端口

~~~shell
#例如暴露服务端口写错时，修改端口
kubectl expose deployment nginx-app --port=30000 --target-port=8000
#查看
kubectl get svc
NAME         TYPE        CLUSTER-IP    EXTERNAL-IP   PORT(S)     AGE
kubernetes   ClusterIP   10.96.0.1     <none>        443/TCP     18h
nginx-app    ClusterIP   10.98.80.32   <none>        30000/TCP   8s
#方法，修改端口
kubectl edit svc nginx-app
# Please edit the object below. Lines beginning with a '#' will be ignored,
# and an empty file will abort the edit. If an error occurs while saving this file will be
# reopened with the relevant failures.
#
apiVersion: v1
kind: Service
metadata:
  creationTimestamp: "2020-12-20T14:08:20Z"
  name: nginx-app
  namespace: default
  resourceVersion: "48194"
  uid: 17d0cdf9-a144-40e4-8d41-75fd60a1473f
spec:
  clusterIP: 10.98.80.32
  clusterIPs:
  - 10.98.80.32
  ports:
#修改目标端口
  - port: 30000
    protocol: TCP
#修改源端口
    targetPort: 80
  selector:
    app: nginx
  sessionAffinity: None
  type: ClusterIP
status:
  loadBalancer: {}

#正确端口，可以访问。实现负载均衡
[root@master111 ~]#  curl 10.98.80.32:30000/hostname.html
nginx-app-654b68c4f7-wbn2s
[root@master111 ~]#  curl 10.98.80.32:30000/hostname.html
nginx-app-654b68c4f7-d84xb
[root@master111 ~]#  curl 10.98.80.32:30000/hostname.html
nginx-app-654b68c4f7-59n7h
[root@master111 ~]#  curl 10.98.80.32:30000/hostname.html
nginx-app-654b68c4f7-8h8f5
[root@master111 ~]#  curl 10.98.80.32:30000/hostname.html


[root@master111 ~]# kubectl edit svc nginx-app
# Please edit the object below. Lines beginning with a '#' will be ignored,
# and an empty file will abort the edit. If an error occurs while saving this file will be
# reopened with the relevant failures.
#
apiVersion: v1
kind: Service
metadata:
  creationTimestamp: "2020-12-20T14:08:20Z"
  name: nginx-app
  namespace: default
  resourceVersion: "48194"
  uid: 17d0cdf9-a144-40e4-8d41-75fd60a1473f
spec:
  clusterIP: 10.98.80.32
  clusterIPs:
  - 10.98.80.32
  ports:
  - port: 30000
    protocol: TCP
    targetPort: 80
  selector:
    app: nginx
  sessionAffinity: None
#修改为NodePort
  type: NodePort
status:
  loadBalancer: {}
#保存
#查看
kubectl get svc
NAME         TYPE        CLUSTER-IP    EXTERNAL-IP   PORT(S)           AGE
kubernetes   ClusterIP   10.96.0.1     <none>        443/TCP           19h
nginx-app    NodePort    10.98.80.32   <none>        30000:32332/TCP   80m
#在客户端，浏览器http://192.168.1.113:32332/ http://192.168.1.112:32332/

~~~

### kube-proxy 开启ipvs

~~~shell
kubectl get configmap kube-proxy -n kube-system -o yaml > kube-proxy-configmap.yaml
sed -i 's/mode: ""/mode: "ipvs"/' kube-proxy-configmap.yaml
kubectl apply -f kube-proxy-configmap.yaml
rm -f kube-proxy-configmap.yaml
kubectl get pod -n kube-system | grep kube-proxy | awk '{system("kubectl delete pod "$1" -n kube-system")}'

#或者用以下方法也可以修改，修改ConfigMap的kube-system/kube-proxy中的config.conf，mode: #"ipvs"

kubectl edit configmap kube-proxy -n kube-system
kubectl get pod -n kube-system | grep kube-proxy | awk '{system("kubectl delete pod "$1" -n kube-system")}

#查看IPVS配置
yum install -y ipvsadm
ipvsadm -ln

#如果出现
ipvsadm -Ln
IP Virtual Server version 1.2.1 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port           Forward Weight ActiveConn InActConn
#执行以上步骤
#验证，负载均衡
[root@master111 ~]# curl 10.98.80.32:30000/hostname.html
nginx-app-654b68c4f7-wbn2s
[root@master111 ~]# curl 10.98.80.32:30000/hostname.html
nginx-app-654b68c4f7-8h8f5
[root@master111 ~]# curl 10.98.80.32:30000/hostname.html
nginx-app-654b68c4f7-d84xb
[root@master111 ~]# curl 10.98.80.32:30000/hostname.html
nginx-app-654b68c4f7-vnthq
[root@master111 ~]# curl 10.98.80.32:30000/hostname.html
nginx-app-654b68c4f7-59n7h


~~~

### 容器的生命周期

~~~shell
kubectl delete deployment --all
kubectl delete pod --all
kubectl get svc 
kubectl delete svc 
kubectl delete svc nginx-app
~~~

### master-00

~~~shell
kubeadm join 192.168.56.135:6443 --token kd26i6.rfava620gheg3h2k \
    --discovery-token-ca-cert-hash sha256:5812b55daa59ac99c407dd322be80702004f66babb609d42ba4ccdab2c2776a9

~~~

docker image 打包成tar包:
docker save logmanager:1.0 > logmanager.tar    或者        docker save 1312423bf3ee -o /root/dockerfile/my.tar

然后在load为image时, 用 docker load < my.tar 或者        docker load -i my.tar

### 安装docker-compose 
sudo curl -L https://github.com/docker/compose/releases/download/1.29.1/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose



//
cat <<EOF | sudo tee /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/
enabled=1
gpgcheck=1
repo_gpgcheck=1
gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg
exclude=kubelet kubeadm kubectl
EOF


kubeadm init --apiserver-advertise-address 192.168.11.132 --kubernetes-version="v1.20.1" --pod-network-cidr=10.244.0.0/16 --image-repository=registry.aliyuncs.com/google_containers | tee kubeadm-init.log