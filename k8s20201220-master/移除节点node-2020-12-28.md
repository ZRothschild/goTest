# 移除集群节点node

~~~shell

[root@node02 ~]# kubectl drain node02 --delete-local-data --force --ignore-daemonsets
Flag --delete-local-data has been deprecated, This option is deprecated and will be deleted. Use --delete-emptydir-data.
node/node02 cordoned
WARNING: ignoring DaemonSet-managed Pods: kube-system/kube-flannel-ds-d5ngt, kube-system/kube-proxy-r6bjt
node/node02 drained

[root@node02 ~]# kubectl delete node node02
node "node02" deleted

[root@node02 ~]# kubeadm reset
[reset] Reading configuration from the cluster...

[root@node02 ~]# ifconfig flannel.1 down

[root@node02 ~]# ip link delete flannel.1


[root@master01 ~]# kubectl delete node node02
Error from server (NotFound): nodes "node02" not found


[root@master01 ~]# kubeadm token create  --print-join-command
kubeadm join 192.168.1.160:6443 --token xt4bqn.3x7a9tuu7j6dimbo     --discovery-token-ca-cert-hash sha256:ea0c1b67e3e9502731aa58838b3ad524a54691954b3e90372b9994b0fa4d1ae5

kubeadm join 192.168.1.160:6443 --token xt4bqn.3x7a9tuu7j6dimbo     --discovery-token-ca-cert-hash sha256:ea0c1b67e3e9502731aa58838b3ad524a54691954b3e90372b9994b0fa4d1ae5

[root@node02 ~]# kubeadm join 192.168.1.160:6443 --token xt4bqn.3x7a9tuu7j6dimbo     --discovery-token-ca-cert-hash sha256:ea0c1b67e3e9502731aa58838b3ad524a54691954b3e90372b9994b0fa4d1ae5

[root@master01 ~]# scp -r /etc/kubernetes/admin.conf root@192.168.1.162:/etc/kubernetes/
root@192.168.1.162's password:
admin.conf                   

[root@node02 ~]# cat << EOF >> ~/.bashrc
export KUBECONFIG=/etc/kubernetes/admin.conf
EOF
[root@node02 ~]# source ~/.bashrc
[root@node02 ~]# kubectl get nodes
NAME       STATUS   ROLES                  AGE    VERSION
master01   Ready    control-plane,master   40m    v1.20.1
node01     Ready    <none>                 37m    v1.20.1
node02     Ready    <none>                 102s   v1.20.1

[root@node02 ~]# ifconfig
docker0: flags=4099<UP,BROADCAST,MULTICAST>  mtu 1500
        inet 172.17.0.1  netmask 255.255.0.0  broadcast 172.17.255.255
        ether 02:42:09:5e:01:79  txqueuelen 0  (Ethernet)
        RX packets 0  bytes 0 (0.0 B)
        RX errors 0  dropped 0  overruns 0  frame 0
        TX packets 0  bytes 0 (0.0 B)
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0

ens33: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500
        inet 192.168.1.162  netmask 255.255.255.0  broadcast 192.168.1.255
        inet6 fe80::18a5:5097:934a:396a  prefixlen 64  scopeid 0x20<link>
        inet6 fe80::41d7:ce82:82f8:a983  prefixlen 64  scopeid 0x20<link>
        inet6 fe80::434d:a270:160d:8c7  prefixlen 64  scopeid 0x20<link>
        ether 00:0c:29:5e:a5:d3  txqueuelen 1000  (Ethernet)
        RX packets 288986  bytes 414016538 (394.8 MiB)
        RX errors 0  dropped 0  overruns 0  frame 0
        TX packets 120320  bytes 9226892 (8.7 MiB)
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0

flannel.1: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1450




~~~



# 向集群添加node节点



~~~shell
[root@node03 ~]# sed -i 's/^SELINUX=enforcing$/SELINUX=disabled/' /etc/selinux/config && setenforce 0
[root@node03 ~]# sed -i '11s/\/dev/# \/dev/g' /etc/fstab && swapoff -a

[root@node03 ~]# yum install -y chrony

[root@node03 ~]# systemctl restart chronyd && systemctl enable chronyd &&  systemctl status chronyd
[root@node03 ~]# systemctl stop firewalld && systemctl disable firewalld

[root@node03 ~]# yum install -y epel-release

[root@node03 ~]# cat > /etc/yum.repos.d/epel.repo <<"EOF"
[epel]
name=Extra Packages for Enterprise Linux 7 - $basearch
baseurl=https://mirrors.tuna.tsinghua.edu.cn/epel/7/$basearch
#mirrorlist=https://mirrors.fedoraproject.org/metalink?repo=epel-7&arch=$basearch
failovermethod=priority
enabled=1
gpgcheck=1
gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL-7

[epel-debuginfo]
name=Extra Packages for Enterprise Linux 7 - $basearch - Debug
baseurl=https://mirrors.tuna.tsinghua.edu.cn/epel/7/$basearch/debug
#mirrorlist=https://mirrors.fedoraproject.org/metalink?repo=epel-debug-7&arch=$basearch
failovermethod=priority
enabled=0
gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL-7
gpgcheck=1

[epel-source]
name=Extra Packages for Enterprise Linux 7 - $basearch - Source
baseurl=https://mirrors.tuna.tsinghua.edu.cn/epel/7/SRPMS
#mirrorlist=https://mirrors.fedoraproject.org/metalink?repo=epel-source-7&arch=$basearch
failovermethod=priority
enabled=0
gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL-7
gpgcheck=1
EOF

[root@node03 ~]# yum clean all && yum makecache
[root@node03 ~]# mkdir /etc/yum.repos.d/ori &&  mv /etc/yum.repos.d/CentOS-* /etc/yum.repos.d/ori/
[root@node03 ~]# cat > /etc/yum.repos.d/CentOS-Base.repo << "EOF"
# CentOS-Base.repo
#
# The mirror system uses the connecting IP address of the client and the
# update status of each mirror to pick mirrors that are updated to and
# geographically close to the client.  You should use this for CentOS updates
# unless you are manually picking other mirrors.
#
# If the mirrorlist= does not work for you, as a fall back you can try the
# remarked out baseurl= line instead.
#
#

[base]
name=CentOS-$releasever - Base
baseurl=https://mirrors.tuna.tsinghua.edu.cn/centos/$releasever/os/$basearch/
#mirrorlist=http://mirrorlist.centos.org/?release=$releasever&arch=$basearch&repo=os
gpgcheck=1
gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7

#released updates
[updates]
name=CentOS-$releasever - Updates
baseurl=https://mirrors.tuna.tsinghua.edu.cn/centos/$releasever/updates/$basearch/
#mirrorlist=http://mirrorlist.centos.org/?release=$releasever&arch=$basearch&repo=updates
gpgcheck=1
gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7

#additional packages that may be useful
[extras]
name=CentOS-$releasever - Extras
baseurl=https://mirrors.tuna.tsinghua.edu.cn/centos/$releasever/extras/$basearch/
#mirrorlist=http://mirrorlist.centos.org/?release=$releasever&arch=$basearch&repo=extras
gpgcheck=1
gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7

#additional packages that extend functionality of existing packages
[centosplus]
name=CentOS-$releasever - Plus
baseurl=https://mirrors.tuna.tsinghua.edu.cn/centos/$releasever/centosplus/$basearch/
#mirrorlist=http://mirrorlist.centos.org/?release=$releasever&arch=$basearch&repo=centosplus
gpgcheck=1
enabled=0
gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7
EOF

[root@node03 ~]# yum install -y ipset ipvsadm
[root@node03 ~]# cat > /etc/sysconfig/modules/ipvs.modules <<EOF
#!/bin/bash
modprobe -- ip_vs
modprobe -- ip_vs_rr
modprobe -- ip_vs_wrr
modprobe -- ip_vs_sh
modprobe -- nf_conntrack
EOF

[root@node03 ~]# chmod +x /etc/sysconfig/modules/ipvs.modules
[root@node03 ~]# bash /etc/sysconfig/modules/ipvs.modules
[root@node03 ~]# cat > /etc/sysctl.d/k8s.conf <<EOF
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
net.ipv4.ip_nonlocal_bind = 1
net.ipv4.ip_forward = 1
vm.swappiness=0
EOF

[root@node03 ~]# modprobe br_netfilter
[root@node03 ~]# sysctl -p /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
net.ipv4.ip_nonlocal_bind = 1
net.ipv4.ip_forward = 1
vm.swappiness = 0

[root@node03 ~]# echo "* soft nofile 65536" >> /etc/security/limits.conf
[root@node03 ~]# echo "* hard nofile 65536" >> /etc/security/limits.conf
[root@node03 ~]# wget -P /etc/yum.repos.d/ http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo
--2020-12-28 23:09:40--  http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo
[root@node03 ~]# yum install -y docker-ce

[root@node03 ~]# [ ! -d /etc/docker ] && mkdir /etc/docker
[root@node03 ~]# cat > /etc/docker/daemon.json <<EOF
{
  "exec-opts": ["native.cgroupdriver=systemd"],
  "log-driver": "json-file",
  "log-opts": {
    "max-size": "100m"
  },
  "storage-driver": "overlay2",
  "storage-opts": [
    "overlay2.override_kernel_check=true"
  ],
  "registry-mirrors": ["https://uyah70su.mirror.aliyuncs.com"],
  "insecure-registries": [
    "www.harbor.org",
    "www.harbor.mobi"
  ]
}
EOF

{
  "exec-opts": ["native.cgroupdriver=systemd"],
  "log-driver": "json-file",
  "log-opts": {
    "max-size": "100m"
  },
  "storage-driver": "overlay2",
  "storage-opts": [
    "overlay2.override_kernel_check=true"
  ],
  "registry-mirrors": ["https://uyah70su.mirror.aliyuncs.com"]
}
EOF



[root@node03 ~]# systemctl daemon-reload && systemctl restart docker && systemctl enable docker
[root@node03 ~]# cat <<EOF > /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64
enabled=1
gpgcheck=1
repo_gpgcheck=1
gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg
EOF


[root@node03 ~]# yum install -y kubeadm kubelet kubectl
[root@node03 ~]# systemctl enable kubelet && systemctl start kubelet

[root@master01 ~]# kubeadm token create  --print-join-command
kubeadm join 192.168.1.160:6443 --token nlma8y.t86gvw3aejj3q1m0     --discovery-token-ca-cert-hash sha256:ea0c1b67e3e9502731aa58838b3ad524a54691954b3e90372b9994b0fa4d1ae5

[root@node03 ~]# kubeadm join 192.168.1.160:6443 --token nlma8y.t86gvw3aejj3q1m0     --discovery-token-ca-cert-hash sha256:ea0c1b67e3e9502731aa58838b3ad524a54691954b3e90372b9994b0fa4d1ae5

[root@node03 ~]# kubectl get nodes
The connection to the server localhost:8080 was refused - did you specify the right host or port?

[root@master01 ~]# scp -r /etc/kubernetes/admin.conf root@192.168.1.163:/etc/kubernetes/
root@192.168.1.163's password:
admin.conf 

[root@node03 ~]# cat << EOF >> ~/.bashrc
export KUBECONFIG=/etc/kubernetes/admin.conf
EOF
[root@node03 ~]# source ~/.bashrc

[root@node03 ~]# kubectl get nodes
NAME       STATUS     ROLES                  AGE    VERSION
master01   Ready      control-plane,master   96m    v1.20.1
node01     Ready      <none>                 93m    v1.20.1
node02     Ready      <none>                 58m    v1.20.1
node03     NotReady   <none>                 2m9s   v1.20.1

[root@node03 ~]# ifconfig
docker0: flags=4099<UP,BROADCAST,MULTICAST>  mtu 1500
        inet 172.17.0.1  netmask 255.255.0.0  broadcast 172.17.255.255
        ether 02:42:96:c5:1f:9a  txqueuelen 0  (Ethernet)
        RX packets 0  bytes 0 (0.0 B)
        RX errors 0  dropped 0  overruns 0  frame 0
        TX packets 0  bytes 0 (0.0 B)
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0

ens33: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500
        inet 192.168.1.163  netmask 255.255.255.0  broadcast 192.168.1.255
        inet6 fe80::18a5:5097:934a:396a  prefixlen 64  scopeid 0x20<link>
        inet6 fe80::41d7:ce82:82f8:a983  prefixlen 64  scopeid 0x20<link>
        inet6 fe80::434d:a270:160d:8c7  prefixlen 64  scopeid 0x20<link>
        ether 00:0c:29:e3:3a:05  txqueuelen 1000  (Ethernet)
        RX packets 236764  bytes 342168221 (326.3 MiB)
        RX errors 0  dropped 0  overruns 0  frame 0
        TX packets 100925  bytes 7685040 (7.3 MiB)
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0

flannel.1: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1450
        inet 10.244.4.0  netmask 255.255.255.255  broadcast 10.244.4.0
        inet6 fe80::de:e4ff:feec:dcdb  prefixlen 64  scopeid 0x20<link>
        ether 02:de:e4:ec:dc:db  txqueuelen 0  (Ethernet)
        RX packets 0  bytes 0 (0.0 B)
        RX errors 0  dropped 0  overruns 0  frame 0
        TX packets 0  bytes 0 (0.0 B)
        TX errors 0  dropped 8 overruns 0  carrier 0  collisions 0

[root@node03 ~]# kubectl get nodes
NAME       STATUS   ROLES                  AGE    VERSION
master01   Ready    control-plane,master   97m    v1.20.1
node01     Ready    <none>                 94m    v1.20.1
node02     Ready    <none>                 59m    v1.20.1
node03     Ready    <none>                 3m3s   v1.20.1



~~~



### 每个节点（master，node）配置

~~~shell
[root@node01 ~]# vi /etc/docker/daemon.json
{
  "exec-opts": ["native.cgroupdriver=systemd"],
  "log-driver": "json-file",
  "log-opts": {
    "max-size": "100m"
  },
  "storage-driver": "overlay2",
  "storage-opts": [
    "overlay2.override_kernel_check=true"
  ],
  "registry-mirrors": ["https://uyah70su.mirror.aliyuncs.com"],
  "insecure-registries": [
    "www.harbor.org",
    "www.harbor.mobi"
  ]
}
[root@node01 ~]# systemctl restart docker

[root@master01 ~]# cat >> /etc/hosts <<EOF
192.168.1.110 www.harbor.mobi
EOF

## 每个节点（master，node），添加
[root@master01 ~]# cat >> /etc/hosts <<EOF
192.168.1.164 node04
EOF

[root@node01 ~]# scp /etc/docker/daemon.json  root@192.168.1.160:/etc/docker/
[root@node01 ~]# scp /etc/docker/daemon.json  root@192.168.1.162:/etc/docker/
[root@node01 ~]# scp /etc/docker/daemon.json  root@192.168.1.163:/etc/docker/

[root@master01 ~]# docker login https://www.harbor.mobi
Username: admin
Password:
WARNING! Your password will be stored unencrypted in /root/.docker/config.json.
Configure a credential helper to remove this warning. See
https://docs.docker.com/engine/reference/commandline/login/#credentials-store

Login Succeeded



~~~

### 测试

~~~shell
[root@master01 ~]# kubectl apply -f nginx.yaml
deployment.apps/nginx-app created

[root@master01 ~]# kubectl get po -o wide
NAME                         READY   STATUS    RESTARTS   AGE   IP            NODE     NOMINATED NODE   READINESS GATES
nginx-app-654b68c4f7-56fgs   1/1     Running   0          18s   10.244.4.10   node03   <none>           <none>
nginx-app-654b68c4f7-8gls5   1/1     Running   0          18s   10.244.1.7    node01   <none>           <none>
nginx-app-654b68c4f7-8lpqk   1/1     Running   0          18s   10.244.4.8    node03   <none>           <none>
nginx-app-654b68c4f7-gqml4   1/1     Running   0          18s   10.244.3.10   node02   <none>           <none>
nginx-app-654b68c4f7-hpvcc   1/1     Running   0          18s   10.244.3.11   node02   <none>           <none>
nginx-app-654b68c4f7-jhzxc   1/1     Running   0          18s   10.244.4.9    node03   <none>           <none>
nginx-app-654b68c4f7-jm8zd   1/1     Running   0          18s   10.244.1.5    node01   <none>           <none>
nginx-app-654b68c4f7-pmzkk   1/1     Running   0          18s   10.244.3.12   node02   <none>           <none>
nginx-app-654b68c4f7-qsrv8   1/1     Running   0          18s   10.244.1.8    node01   <none>           <none>
nginx-app-654b68c4f7-z62jz   1/1     Running   0          18s   10.244.1.6    node01   <none>           <none>

~~~

### 补全

~~~shell
yum install -y bash-completion
echo 'source /usr/share/bash-completion/bash_completion' >> /etc/profile
source /etc/profile
echo "source <(kubectl completion bash)" >> ~/.bashrc
source ~/.bashrc
~~~

